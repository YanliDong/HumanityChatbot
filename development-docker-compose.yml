version: "3.3"

services:
  api_server:
    command: python /code/api-app.py
    build:
      context: .
      dockerfile: api/API.Dockerfile
    environment:
      CONTAINER: api_server
      PORT: ${PORT}
      LLM_HOST: ${LLM_HOST}
      LOGIN_KEY: ${LOGIN_KEY}
      BASE_API_URL: http://humanity:10001/api/
    ports:
      - ${PORT}:${PORT}
    volumes:
      - ./api:/code/api

  humanity_mock_server:
    command: python /code/api-humanity-mock.py
    hostname: humanity
    build:
      context: .
      dockerfile: mock_humanity_server/API.Dockerfile
    environment:
      CONTAINER: mock_humanity_server
      PORT: 10001
    ports:
      - 10001:10001
    volumes:
      - ./mock_humanity_server:/code/mock_humanity_server

  openapi_server:
    hostname: vllm
    build:
      context: .
      dockerfile: vLLMServer.Dockerfile
    volumes:
      - huggingface_cache:/root/.cache/huggingface
    ports:
      - '8000:8000'

volumes:
  huggingface_cache: